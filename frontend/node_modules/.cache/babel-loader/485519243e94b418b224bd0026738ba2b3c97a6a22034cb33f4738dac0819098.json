{"ast":null,"code":"import _toConsumableArray from \"/Users/abel/Documents/Code-Experiments/cool-storage-api/frontend/node_modules/@babel/runtime/helpers/esm/toConsumableArray.js\";\n/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenType} TokenType\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * @callback Restore\n * @returns {undefined}\n *\n * @typedef Info\n * @property {Restore} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {undefined}\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { push, splice } from 'micromark-util-chunked';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  var point = Object.assign(from ? Object.assign({}, from) : {\n    line: 1,\n    column: 1,\n    offset: 0\n  }, {\n    _index: 0,\n    _bufferIndex: -1\n  });\n  /** @type {Record<string, number>} */\n  var columnStart = {};\n  /** @type {Array<Construct>} */\n  var resolveAllConstructs = [];\n  /** @type {Array<Chunk>} */\n  var chunks = [];\n  /** @type {Array<Token>} */\n  var stack = [];\n  /** @type {boolean | undefined} */\n  var consumed = true;\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  var effects = {\n    consume: consume,\n    enter: enter,\n    exit: exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  };\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  var context = {\n    previous: null,\n    code: null,\n    containerState: {},\n    events: [],\n    parser: parser,\n    sliceStream: sliceStream,\n    sliceSerialize: sliceSerialize,\n    now: now,\n    defineSkip: defineSkip,\n    write: write\n  };\n\n  /**\n   * The state function.\n   *\n   * @type {State | undefined}\n   */\n  var state = initialize.tokenize.call(context, effects);\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  var expectedCode;\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  }\n  return context;\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice);\n    main();\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n    addResult(initialize, 0);\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs);\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    var _point = point,\n      line = _point.line,\n      column = _point.column,\n      offset = _point.offset,\n      _index = _point._index,\n      _bufferIndex = _point._bufferIndex;\n    return {\n      line: line,\n      column: column,\n      offset: offset,\n      _index: _index,\n      _bufferIndex: _bufferIndex\n    };\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {undefined}\n   */\n  function main() {\n    /** @type {number} */\n    var chunkIndex;\n    while (point._index < chunks.length) {\n      var chunk = chunks[point._index];\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {undefined}\n   */\n  function go(code) {\n    consumed = undefined;\n    expectedCode = code;\n    state = state(code);\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++;\n\n      // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code;\n\n    // Mark as consumed.\n    consumed = true;\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    var token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    var token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore();\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   */\n  function constructFactory(onreturn, fields) {\n    return hook;\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | Construct | ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State | undefined} [bogusState]\n     * @returns {State}\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Array<Construct>} */\n      var listOfConstructs;\n      /** @type {number} */\n      var constructIndex;\n      /** @type {Construct} */\n      var currentConstruct;\n      /** @type {Info} */\n      var info;\n      return Array.isArray(constructs) /* c8 ignore next 1 */ ? handleListOfConstructs(constructs) : 'tokenize' in constructs ?\n      // @ts-expect-error Looks like a construct.\n      handleListOfConstructs([constructs]) : handleMapOfConstructs(constructs);\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n      function handleMapOfConstructs(map) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          var def = code !== null && map[code];\n          var all = code !== null && map.null;\n          var list = [].concat(_toConsumableArray(Array.isArray(def) ? def : def ? [def] : []), _toConsumableArray(Array.isArray(all) ? all : all ? [all] : []));\n          return handleListOfConstructs(list)(code);\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Array<Construct>} list\n       * @returns {State}\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        if (list.length === 0) {\n          return bogusState;\n        }\n        return handleConstruct(list[constructIndex]);\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n      function handleConstruct(construct) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          // Always populated by defaults.\n\n          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {\n            return nok(code);\n          }\n          return construct.tokenize.call(\n          // If we do have fields, create an object w/ `context` as its\n          // prototype.\n          // This allows a “live binding”, which is needed for `interrupt`.\n          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true;\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true;\n        info.restore();\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n        return bogusState;\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {undefined}\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct);\n    }\n    if (construct.resolve) {\n      splice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n  function store() {\n    var startPoint = now();\n    var startPrevious = context.previous;\n    var startCurrentConstruct = context.currentConstruct;\n    var startEventsIndex = context.events.length;\n    var startStack = Array.from(stack);\n    return {\n      restore: restore,\n      from: startEventsIndex\n    };\n\n    /**\n     * Restore state.\n     *\n     * @returns {undefined}\n     */\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {undefined}\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Array<Chunk>} chunks\n * @param {Pick<Token, 'end' | 'start'>} token\n * @returns {Array<Chunk>}\n */\nfunction sliceChunks(chunks, token) {\n  var startIndex = token.start._index;\n  var startBufferIndex = token.start._bufferIndex;\n  var endIndex = token.end._index;\n  var endBufferIndex = token.end._bufferIndex;\n  /** @type {Array<Chunk>} */\n  var view;\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];\n  } else {\n    view = chunks.slice(startIndex, endIndex);\n    if (startBufferIndex > -1) {\n      var head = view[0];\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex);\n      } else {\n        view.shift();\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex));\n    }\n  }\n  return view;\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Array<Chunk>} chunks\n * @param {boolean | undefined} [expandTabs=false]\n * @returns {string}\n */\nfunction serializeChunks(chunks, expandTabs) {\n  var index = -1;\n  /** @type {Array<string>} */\n  var result = [];\n  /** @type {boolean | undefined} */\n  var atTab;\n  while (++index < chunks.length) {\n    var chunk = chunks[index];\n    /** @type {string} */\n    var value = void 0;\n    if (typeof chunk === 'string') {\n      value = chunk;\n    } else switch (chunk) {\n      case -5:\n        {\n          value = '\\r';\n          break;\n        }\n      case -4:\n        {\n          value = '\\n';\n          break;\n        }\n      case -3:\n        {\n          value = '\\r' + '\\n';\n          break;\n        }\n      case -2:\n        {\n          value = expandTabs ? ' ' : '\\t';\n          break;\n        }\n      case -1:\n        {\n          if (!expandTabs && atTab) continue;\n          value = ' ';\n          break;\n        }\n      default:\n        {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk);\n        }\n    }\n    atTab = chunk === -2;\n    result.push(value);\n  }\n  return result.join('');\n}","map":{"version":3,"names":["markdownLineEnding","push","splice","resolveAll","createTokenizer","parser","initialize","from","point","Object","assign","line","column","offset","_index","_bufferIndex","columnStart","resolveAllConstructs","chunks","stack","consumed","effects","consume","enter","exit","attempt","constructFactory","onsuccessfulconstruct","check","onsuccessfulcheck","interrupt","context","previous","code","containerState","events","sliceStream","sliceSerialize","now","defineSkip","write","state","tokenize","call","expectedCode","slice","main","length","addResult","token","expandTabs","serializeChunks","sliceChunks","_point","value","accountForPotentialSkip","chunkIndex","chunk","go","charCodeAt","undefined","type","fields","start","pop","end","construct","info","_","restore","onreturn","hook","constructs","returnState","bogusState","listOfConstructs","constructIndex","currentConstruct","Array","isArray","handleListOfConstructs","handleMapOfConstructs","map","def","all","null","list","concat","_toConsumableArray","handleConstruct","store","partial","name","disable","includes","nok","create","ok","resolve","resolveTo","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","startIndex","startBufferIndex","endIndex","endBufferIndex","view","head","shift","index","result","atTab","String","fromCharCode","join"],"sources":["/Users/abel/Documents/Code-Experiments/cool-storage-api/frontend/node_modules/micromark/lib/create-tokenizer.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenType} TokenType\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * @callback Restore\n * @returns {undefined}\n *\n * @typedef Info\n * @property {Restore} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {undefined}\n */\n\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {push, splice} from 'micromark-util-chunked'\nimport {resolveAll} from 'micromark-util-resolve-all'\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(\n    from\n      ? Object.assign({}, from)\n      : {\n          line: 1,\n          column: 1,\n          offset: 0\n        },\n    {\n      _index: 0,\n      _bufferIndex: -1\n    }\n  )\n  /** @type {Record<string, number>} */\n  const columnStart = {}\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = []\n  /** @type {Array<Chunk>} */\n  let chunks = []\n  /** @type {Array<Token>} */\n  let stack = []\n  /** @type {boolean | undefined} */\n  let consumed = true\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  }\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    previous: null,\n    code: null,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  }\n\n  /**\n   * The state function.\n   *\n   * @type {State | undefined}\n   */\n  let state = initialize.tokenize.call(context, effects)\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n  return context\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice)\n    main()\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n    addResult(initialize, 0)\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n    return context.events\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs)\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {line, column, offset, _index, _bufferIndex} = point\n    return {\n      line,\n      column,\n      offset,\n      _index,\n      _bufferIndex\n    }\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {undefined}\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index]\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {undefined}\n   */\n  function go(code) {\n    consumed = undefined\n    expectedCode = code\n    state = state(code)\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++\n\n      // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code\n\n    // Mark as consumed.\n    consumed = true\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {}\n    token.type = type\n    token.start = now()\n    context.events.push(['enter', token, context])\n    stack.push(token)\n    return token\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop()\n    token.end = now()\n    context.events.push(['exit', token, context])\n    return token\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore()\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   */\n  function constructFactory(onreturn, fields) {\n    return hook\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | Construct | ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State | undefined} [bogusState]\n     * @returns {State}\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Array<Construct>} */\n      let listOfConstructs\n      /** @type {number} */\n      let constructIndex\n      /** @type {Construct} */\n      let currentConstruct\n      /** @type {Info} */\n      let info\n      return Array.isArray(constructs) /* c8 ignore next 1 */\n        ? handleListOfConstructs(constructs)\n        : 'tokenize' in constructs\n        ? // @ts-expect-error Looks like a construct.\n          handleListOfConstructs([constructs])\n        : handleMapOfConstructs(constructs)\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n      function handleMapOfConstructs(map) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          const def = code !== null && map[code]\n          const all = code !== null && map.null\n          const list = [\n            // To do: add more extension tests.\n            /* c8 ignore next 2 */\n            ...(Array.isArray(def) ? def : def ? [def] : []),\n            ...(Array.isArray(all) ? all : all ? [all] : [])\n          ]\n          return handleListOfConstructs(list)(code)\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Array<Construct>} list\n       * @returns {State}\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n        if (list.length === 0) {\n          return bogusState\n        }\n        return handleConstruct(list[constructIndex])\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n      function handleConstruct(construct) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          // Always populated by defaults.\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.includes(construct.name)\n          ) {\n            return nok(code)\n          }\n          return construct.tokenize.call(\n            // If we do have fields, create an object w/ `context` as its\n            // prototype.\n            // This allows a “live binding”, which is needed for `interrupt`.\n            fields ? Object.assign(Object.create(context), fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true\n        info.restore()\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n        return bogusState\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {undefined}\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct)\n    }\n    if (construct.resolve) {\n      splice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n  function store() {\n    const startPoint = now()\n    const startPrevious = context.previous\n    const startCurrentConstruct = context.currentConstruct\n    const startEventsIndex = context.events.length\n    const startStack = Array.from(stack)\n    return {\n      restore,\n      from: startEventsIndex\n    }\n\n    /**\n     * Restore state.\n     *\n     * @returns {undefined}\n     */\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {undefined}\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Array<Chunk>} chunks\n * @param {Pick<Token, 'end' | 'start'>} token\n * @returns {Array<Chunk>}\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index\n  const startBufferIndex = token.start._bufferIndex\n  const endIndex = token.end._index\n  const endBufferIndex = token.end._bufferIndex\n  /** @type {Array<Chunk>} */\n  let view\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n    if (startBufferIndex > -1) {\n      const head = view[0]\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex)\n      } else {\n        view.shift()\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n  return view\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Array<Chunk>} chunks\n * @param {boolean | undefined} [expandTabs=false]\n * @returns {string}\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1\n  /** @type {Array<string>} */\n  const result = []\n  /** @type {boolean | undefined} */\n  let atTab\n  while (++index < chunks.length) {\n    const chunk = chunks[index]\n    /** @type {string} */\n    let value\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else\n      switch (chunk) {\n        case -5: {\n          value = '\\r'\n          break\n        }\n        case -4: {\n          value = '\\n'\n          break\n        }\n        case -3: {\n          value = '\\r' + '\\n'\n          break\n        }\n        case -2: {\n          value = expandTabs ? ' ' : '\\t'\n          break\n        }\n        case -1: {\n          if (!expandTabs && atTab) continue\n          value = ' '\n          break\n        }\n        default: {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk)\n        }\n      }\n    atTab = chunk === -2\n    result.push(value)\n  }\n  return result.join('')\n}\n"],"mappings":";AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAAQA,kBAAkB,QAAO,0BAA0B;AAC3D,SAAQC,IAAI,EAAEC,MAAM,QAAO,wBAAwB;AACnD,SAAQC,UAAU,QAAO,4BAA4B;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,SAASC,eAAeA,CAACC,MAAM,EAAEC,UAAU,EAAEC,IAAI,EAAE;EACxD;EACA,IAAIC,KAAK,GAAGC,MAAM,CAACC,MAAM,CACvBH,IAAI,GACAE,MAAM,CAACC,MAAM,CAAC,CAAC,CAAC,EAAEH,IAAI,CAAC,GACvB;IACEI,IAAI,EAAE,CAAC;IACPC,MAAM,EAAE,CAAC;IACTC,MAAM,EAAE;EACV,CAAC,EACL;IACEC,MAAM,EAAE,CAAC;IACTC,YAAY,EAAE,CAAC;EACjB,CACF,CAAC;EACD;EACA,IAAMC,WAAW,GAAG,CAAC,CAAC;EACtB;EACA,IAAMC,oBAAoB,GAAG,EAAE;EAC/B;EACA,IAAIC,MAAM,GAAG,EAAE;EACf;EACA,IAAIC,KAAK,GAAG,EAAE;EACd;EACA,IAAIC,QAAQ,GAAG,IAAI;;EAEnB;AACF;AACA;AACA;AACA;EACE,IAAMC,OAAO,GAAG;IACdC,OAAO,EAAPA,OAAO;IACPC,KAAK,EAALA,KAAK;IACLC,IAAI,EAAJA,IAAI;IACJC,OAAO,EAAEC,gBAAgB,CAACC,qBAAqB,CAAC;IAChDC,KAAK,EAAEF,gBAAgB,CAACG,iBAAiB,CAAC;IAC1CC,SAAS,EAAEJ,gBAAgB,CAACG,iBAAiB,EAAE;MAC7CC,SAAS,EAAE;IACb,CAAC;EACH,CAAC;;EAED;AACF;AACA;AACA;AACA;EACE,IAAMC,OAAO,GAAG;IACdC,QAAQ,EAAE,IAAI;IACdC,IAAI,EAAE,IAAI;IACVC,cAAc,EAAE,CAAC,CAAC;IAClBC,MAAM,EAAE,EAAE;IACV9B,MAAM,EAANA,MAAM;IACN+B,WAAW,EAAXA,WAAW;IACXC,cAAc,EAAdA,cAAc;IACdC,GAAG,EAAHA,GAAG;IACHC,UAAU,EAAVA,UAAU;IACVC,KAAK,EAALA;EACF,CAAC;;EAED;AACF;AACA;AACA;AACA;EACE,IAAIC,KAAK,GAAGnC,UAAU,CAACoC,QAAQ,CAACC,IAAI,CAACZ,OAAO,EAAEV,OAAO,CAAC;;EAEtD;AACF;AACA;AACA;AACA;EACE,IAAIuB,YAAY;EAChB,IAAItC,UAAU,CAACH,UAAU,EAAE;IACzBc,oBAAoB,CAAChB,IAAI,CAACK,UAAU,CAAC;EACvC;EACA,OAAOyB,OAAO;;EAEd;EACA,SAASS,KAAKA,CAACK,KAAK,EAAE;IACpB3B,MAAM,GAAGjB,IAAI,CAACiB,MAAM,EAAE2B,KAAK,CAAC;IAC5BC,IAAI,CAAC,CAAC;;IAEN;IACA,IAAI5B,MAAM,CAACA,MAAM,CAAC6B,MAAM,GAAG,CAAC,CAAC,KAAK,IAAI,EAAE;MACtC,OAAO,EAAE;IACX;IACAC,SAAS,CAAC1C,UAAU,EAAE,CAAC,CAAC;;IAExB;IACAyB,OAAO,CAACI,MAAM,GAAGhC,UAAU,CAACc,oBAAoB,EAAEc,OAAO,CAACI,MAAM,EAAEJ,OAAO,CAAC;IAC1E,OAAOA,OAAO,CAACI,MAAM;EACvB;;EAEA;EACA;EACA;;EAEA;EACA,SAASE,cAAcA,CAACY,KAAK,EAAEC,UAAU,EAAE;IACzC,OAAOC,eAAe,CAACf,WAAW,CAACa,KAAK,CAAC,EAAEC,UAAU,CAAC;EACxD;;EAEA;EACA,SAASd,WAAWA,CAACa,KAAK,EAAE;IAC1B,OAAOG,WAAW,CAAClC,MAAM,EAAE+B,KAAK,CAAC;EACnC;;EAEA;EACA,SAASX,GAAGA,CAAA,EAAG;IACb;IACA,IAAAe,MAAA,GAAqD7C,KAAK;MAAnDG,IAAI,GAAA0C,MAAA,CAAJ1C,IAAI;MAAEC,MAAM,GAAAyC,MAAA,CAANzC,MAAM;MAAEC,MAAM,GAAAwC,MAAA,CAANxC,MAAM;MAAEC,MAAM,GAAAuC,MAAA,CAANvC,MAAM;MAAEC,YAAY,GAAAsC,MAAA,CAAZtC,YAAY;IACjD,OAAO;MACLJ,IAAI,EAAJA,IAAI;MACJC,MAAM,EAANA,MAAM;MACNC,MAAM,EAANA,MAAM;MACNC,MAAM,EAANA,MAAM;MACNC,YAAY,EAAZA;IACF,CAAC;EACH;;EAEA;EACA,SAASwB,UAAUA,CAACe,KAAK,EAAE;IACzBtC,WAAW,CAACsC,KAAK,CAAC3C,IAAI,CAAC,GAAG2C,KAAK,CAAC1C,MAAM;IACtC2C,uBAAuB,CAAC,CAAC;EAC3B;;EAEA;EACA;EACA;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,SAAST,IAAIA,CAAA,EAAG;IACd;IACA,IAAIU,UAAU;IACd,OAAOhD,KAAK,CAACM,MAAM,GAAGI,MAAM,CAAC6B,MAAM,EAAE;MACnC,IAAMU,KAAK,GAAGvC,MAAM,CAACV,KAAK,CAACM,MAAM,CAAC;;MAElC;MACA,IAAI,OAAO2C,KAAK,KAAK,QAAQ,EAAE;QAC7BD,UAAU,GAAGhD,KAAK,CAACM,MAAM;QACzB,IAAIN,KAAK,CAACO,YAAY,GAAG,CAAC,EAAE;UAC1BP,KAAK,CAACO,YAAY,GAAG,CAAC;QACxB;QACA,OACEP,KAAK,CAACM,MAAM,KAAK0C,UAAU,IAC3BhD,KAAK,CAACO,YAAY,GAAG0C,KAAK,CAACV,MAAM,EACjC;UACAW,EAAE,CAACD,KAAK,CAACE,UAAU,CAACnD,KAAK,CAACO,YAAY,CAAC,CAAC;QAC1C;MACF,CAAC,MAAM;QACL2C,EAAE,CAACD,KAAK,CAAC;MACX;IACF;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;EACE,SAASC,EAAEA,CAACzB,IAAI,EAAE;IAChBb,QAAQ,GAAGwC,SAAS;IACpBhB,YAAY,GAAGX,IAAI;IACnBQ,KAAK,GAAGA,KAAK,CAACR,IAAI,CAAC;EACrB;;EAEA;EACA,SAASX,OAAOA,CAACW,IAAI,EAAE;IACrB,IAAIjC,kBAAkB,CAACiC,IAAI,CAAC,EAAE;MAC5BzB,KAAK,CAACG,IAAI,EAAE;MACZH,KAAK,CAACI,MAAM,GAAG,CAAC;MAChBJ,KAAK,CAACK,MAAM,IAAIoB,IAAI,KAAK,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;MACnCsB,uBAAuB,CAAC,CAAC;IAC3B,CAAC,MAAM,IAAItB,IAAI,KAAK,CAAC,CAAC,EAAE;MACtBzB,KAAK,CAACI,MAAM,EAAE;MACdJ,KAAK,CAACK,MAAM,EAAE;IAChB;;IAEA;IACA,IAAIL,KAAK,CAACO,YAAY,GAAG,CAAC,EAAE;MAC1BP,KAAK,CAACM,MAAM,EAAE;IAChB,CAAC,MAAM;MACLN,KAAK,CAACO,YAAY,EAAE;;MAEpB;MACA;MACA;MACA,IAAIP,KAAK,CAACO,YAAY,KAAKG,MAAM,CAACV,KAAK,CAACM,MAAM,CAAC,CAACiC,MAAM,EAAE;QACtDvC,KAAK,CAACO,YAAY,GAAG,CAAC,CAAC;QACvBP,KAAK,CAACM,MAAM,EAAE;MAChB;IACF;;IAEA;IACAiB,OAAO,CAACC,QAAQ,GAAGC,IAAI;;IAEvB;IACAb,QAAQ,GAAG,IAAI;EACjB;;EAEA;EACA,SAASG,KAAKA,CAACsC,IAAI,EAAEC,MAAM,EAAE;IAC3B;IACA;IACA,IAAMb,KAAK,GAAGa,MAAM,IAAI,CAAC,CAAC;IAC1Bb,KAAK,CAACY,IAAI,GAAGA,IAAI;IACjBZ,KAAK,CAACc,KAAK,GAAGzB,GAAG,CAAC,CAAC;IACnBP,OAAO,CAACI,MAAM,CAAClC,IAAI,CAAC,CAAC,OAAO,EAAEgD,KAAK,EAAElB,OAAO,CAAC,CAAC;IAC9CZ,KAAK,CAAClB,IAAI,CAACgD,KAAK,CAAC;IACjB,OAAOA,KAAK;EACd;;EAEA;EACA,SAASzB,IAAIA,CAACqC,IAAI,EAAE;IAClB,IAAMZ,KAAK,GAAG9B,KAAK,CAAC6C,GAAG,CAAC,CAAC;IACzBf,KAAK,CAACgB,GAAG,GAAG3B,GAAG,CAAC,CAAC;IACjBP,OAAO,CAACI,MAAM,CAAClC,IAAI,CAAC,CAAC,MAAM,EAAEgD,KAAK,EAAElB,OAAO,CAAC,CAAC;IAC7C,OAAOkB,KAAK;EACd;;EAEA;AACF;AACA;AACA;AACA;EACE,SAAStB,qBAAqBA,CAACuC,SAAS,EAAEC,IAAI,EAAE;IAC9CnB,SAAS,CAACkB,SAAS,EAAEC,IAAI,CAAC5D,IAAI,CAAC;EACjC;;EAEA;AACF;AACA;AACA;AACA;EACE,SAASsB,iBAAiBA,CAACuC,CAAC,EAAED,IAAI,EAAE;IAClCA,IAAI,CAACE,OAAO,CAAC,CAAC;EAChB;;EAEA;AACF;AACA;AACA;AACA;AACA;EACE,SAAS3C,gBAAgBA,CAAC4C,QAAQ,EAAER,MAAM,EAAE;IAC1C,OAAOS,IAAI;;IAEX;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;IACI,SAASA,IAAIA,CAACC,UAAU,EAAEC,WAAW,EAAEC,UAAU,EAAE;MACjD;MACA,IAAIC,gBAAgB;MACpB;MACA,IAAIC,cAAc;MAClB;MACA,IAAIC,gBAAgB;MACpB;MACA,IAAIV,IAAI;MACR,OAAOW,KAAK,CAACC,OAAO,CAACP,UAAU,CAAC,CAAC,yBAC7BQ,sBAAsB,CAACR,UAAU,CAAC,GAClC,UAAU,IAAIA,UAAU;MACxB;MACAQ,sBAAsB,CAAC,CAACR,UAAU,CAAC,CAAC,GACpCS,qBAAqB,CAACT,UAAU,CAAC;;MAErC;AACN;AACA;AACA;AACA;AACA;MACM,SAASS,qBAAqBA,CAACC,GAAG,EAAE;QAClC,OAAOnB,KAAK;;QAEZ;QACA,SAASA,KAAKA,CAAC9B,IAAI,EAAE;UACnB,IAAMkD,GAAG,GAAGlD,IAAI,KAAK,IAAI,IAAIiD,GAAG,CAACjD,IAAI,CAAC;UACtC,IAAMmD,GAAG,GAAGnD,IAAI,KAAK,IAAI,IAAIiD,GAAG,CAACG,IAAI;UACrC,IAAMC,IAAI,MAAAC,MAAA,CAAAC,kBAAA,CAGJV,KAAK,CAACC,OAAO,CAACI,GAAG,CAAC,GAAGA,GAAG,GAAGA,GAAG,GAAG,CAACA,GAAG,CAAC,GAAG,EAAE,GAAAK,kBAAA,CAC3CV,KAAK,CAACC,OAAO,CAACK,GAAG,CAAC,GAAGA,GAAG,GAAGA,GAAG,GAAG,CAACA,GAAG,CAAC,GAAG,EAAE,EAChD;UACD,OAAOJ,sBAAsB,CAACM,IAAI,CAAC,CAACrD,IAAI,CAAC;QAC3C;MACF;;MAEA;AACN;AACA;AACA;AACA;AACA;MACM,SAAS+C,sBAAsBA,CAACM,IAAI,EAAE;QACpCX,gBAAgB,GAAGW,IAAI;QACvBV,cAAc,GAAG,CAAC;QAClB,IAAIU,IAAI,CAACvC,MAAM,KAAK,CAAC,EAAE;UACrB,OAAO2B,UAAU;QACnB;QACA,OAAOe,eAAe,CAACH,IAAI,CAACV,cAAc,CAAC,CAAC;MAC9C;;MAEA;AACN;AACA;AACA;AACA;AACA;MACM,SAASa,eAAeA,CAACvB,SAAS,EAAE;QAClC,OAAOH,KAAK;;QAEZ;QACA,SAASA,KAAKA,CAAC9B,IAAI,EAAE;UACnB;UACA;UACA;UACA;UACAkC,IAAI,GAAGuB,KAAK,CAAC,CAAC;UACdb,gBAAgB,GAAGX,SAAS;UAC5B,IAAI,CAACA,SAAS,CAACyB,OAAO,EAAE;YACtB5D,OAAO,CAAC8C,gBAAgB,GAAGX,SAAS;UACtC;;UAEA;;UAEA,IACEA,SAAS,CAAC0B,IAAI,IACd7D,OAAO,CAAC1B,MAAM,CAACmE,UAAU,CAACqB,OAAO,CAACR,IAAI,CAACS,QAAQ,CAAC5B,SAAS,CAAC0B,IAAI,CAAC,EAC/D;YACA,OAAOG,GAAG,CAAC9D,IAAI,CAAC;UAClB;UACA,OAAOiC,SAAS,CAACxB,QAAQ,CAACC,IAAI;UAC5B;UACA;UACA;UACAmB,MAAM,GAAGrD,MAAM,CAACC,MAAM,CAACD,MAAM,CAACuF,MAAM,CAACjE,OAAO,CAAC,EAAE+B,MAAM,CAAC,GAAG/B,OAAO,EAChEV,OAAO,EACP4E,EAAE,EACFF,GACF,CAAC,CAAC9D,IAAI,CAAC;QACT;MACF;;MAEA;MACA,SAASgE,EAAEA,CAAChE,IAAI,EAAE;QAChBb,QAAQ,GAAG,IAAI;QACfkD,QAAQ,CAACO,gBAAgB,EAAEV,IAAI,CAAC;QAChC,OAAOM,WAAW;MACpB;;MAEA;MACA,SAASsB,GAAGA,CAAC9D,IAAI,EAAE;QACjBb,QAAQ,GAAG,IAAI;QACf+C,IAAI,CAACE,OAAO,CAAC,CAAC;QACd,IAAI,EAAEO,cAAc,GAAGD,gBAAgB,CAAC5B,MAAM,EAAE;UAC9C,OAAO0C,eAAe,CAACd,gBAAgB,CAACC,cAAc,CAAC,CAAC;QAC1D;QACA,OAAOF,UAAU;MACnB;IACF;EACF;;EAEA;AACF;AACA;AACA;AACA;EACE,SAAS1B,SAASA,CAACkB,SAAS,EAAE3D,IAAI,EAAE;IAClC,IAAI2D,SAAS,CAAC/D,UAAU,IAAI,CAACc,oBAAoB,CAAC6E,QAAQ,CAAC5B,SAAS,CAAC,EAAE;MACrEjD,oBAAoB,CAAChB,IAAI,CAACiE,SAAS,CAAC;IACtC;IACA,IAAIA,SAAS,CAACgC,OAAO,EAAE;MACrBhG,MAAM,CACJ6B,OAAO,CAACI,MAAM,EACd5B,IAAI,EACJwB,OAAO,CAACI,MAAM,CAACY,MAAM,GAAGxC,IAAI,EAC5B2D,SAAS,CAACgC,OAAO,CAACnE,OAAO,CAACI,MAAM,CAACU,KAAK,CAACtC,IAAI,CAAC,EAAEwB,OAAO,CACvD,CAAC;IACH;IACA,IAAImC,SAAS,CAACiC,SAAS,EAAE;MACvBpE,OAAO,CAACI,MAAM,GAAG+B,SAAS,CAACiC,SAAS,CAACpE,OAAO,CAACI,MAAM,EAAEJ,OAAO,CAAC;IAC/D;EACF;;EAEA;AACF;AACA;AACA;AACA;EACE,SAAS2D,KAAKA,CAAA,EAAG;IACf,IAAMU,UAAU,GAAG9D,GAAG,CAAC,CAAC;IACxB,IAAM+D,aAAa,GAAGtE,OAAO,CAACC,QAAQ;IACtC,IAAMsE,qBAAqB,GAAGvE,OAAO,CAAC8C,gBAAgB;IACtD,IAAM0B,gBAAgB,GAAGxE,OAAO,CAACI,MAAM,CAACY,MAAM;IAC9C,IAAMyD,UAAU,GAAG1B,KAAK,CAACvE,IAAI,CAACY,KAAK,CAAC;IACpC,OAAO;MACLkD,OAAO,EAAPA,OAAO;MACP9D,IAAI,EAAEgG;IACR,CAAC;;IAED;AACJ;AACA;AACA;AACA;IACI,SAASlC,OAAOA,CAAA,EAAG;MACjB7D,KAAK,GAAG4F,UAAU;MAClBrE,OAAO,CAACC,QAAQ,GAAGqE,aAAa;MAChCtE,OAAO,CAAC8C,gBAAgB,GAAGyB,qBAAqB;MAChDvE,OAAO,CAACI,MAAM,CAACY,MAAM,GAAGwD,gBAAgB;MACxCpF,KAAK,GAAGqF,UAAU;MAClBjD,uBAAuB,CAAC,CAAC;IAC3B;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;EACE,SAASA,uBAAuBA,CAAA,EAAG;IACjC,IAAI/C,KAAK,CAACG,IAAI,IAAIK,WAAW,IAAIR,KAAK,CAACI,MAAM,GAAG,CAAC,EAAE;MACjDJ,KAAK,CAACI,MAAM,GAAGI,WAAW,CAACR,KAAK,CAACG,IAAI,CAAC;MACtCH,KAAK,CAACK,MAAM,IAAIG,WAAW,CAACR,KAAK,CAACG,IAAI,CAAC,GAAG,CAAC;IAC7C;EACF;AACF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASyC,WAAWA,CAAClC,MAAM,EAAE+B,KAAK,EAAE;EAClC,IAAMwD,UAAU,GAAGxD,KAAK,CAACc,KAAK,CAACjD,MAAM;EACrC,IAAM4F,gBAAgB,GAAGzD,KAAK,CAACc,KAAK,CAAChD,YAAY;EACjD,IAAM4F,QAAQ,GAAG1D,KAAK,CAACgB,GAAG,CAACnD,MAAM;EACjC,IAAM8F,cAAc,GAAG3D,KAAK,CAACgB,GAAG,CAAClD,YAAY;EAC7C;EACA,IAAI8F,IAAI;EACR,IAAIJ,UAAU,KAAKE,QAAQ,EAAE;IAC3B;IACAE,IAAI,GAAG,CAAC3F,MAAM,CAACuF,UAAU,CAAC,CAAC5D,KAAK,CAAC6D,gBAAgB,EAAEE,cAAc,CAAC,CAAC;EACrE,CAAC,MAAM;IACLC,IAAI,GAAG3F,MAAM,CAAC2B,KAAK,CAAC4D,UAAU,EAAEE,QAAQ,CAAC;IACzC,IAAID,gBAAgB,GAAG,CAAC,CAAC,EAAE;MACzB,IAAMI,IAAI,GAAGD,IAAI,CAAC,CAAC,CAAC;MACpB,IAAI,OAAOC,IAAI,KAAK,QAAQ,EAAE;QAC5BD,IAAI,CAAC,CAAC,CAAC,GAAGC,IAAI,CAACjE,KAAK,CAAC6D,gBAAgB,CAAC;MACxC,CAAC,MAAM;QACLG,IAAI,CAACE,KAAK,CAAC,CAAC;MACd;IACF;IACA,IAAIH,cAAc,GAAG,CAAC,EAAE;MACtB;MACAC,IAAI,CAAC5G,IAAI,CAACiB,MAAM,CAACyF,QAAQ,CAAC,CAAC9D,KAAK,CAAC,CAAC,EAAE+D,cAAc,CAAC,CAAC;IACtD;EACF;EACA,OAAOC,IAAI;AACb;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS1D,eAAeA,CAACjC,MAAM,EAAEgC,UAAU,EAAE;EAC3C,IAAI8D,KAAK,GAAG,CAAC,CAAC;EACd;EACA,IAAMC,MAAM,GAAG,EAAE;EACjB;EACA,IAAIC,KAAK;EACT,OAAO,EAAEF,KAAK,GAAG9F,MAAM,CAAC6B,MAAM,EAAE;IAC9B,IAAMU,KAAK,GAAGvC,MAAM,CAAC8F,KAAK,CAAC;IAC3B;IACA,IAAI1D,KAAK;IACT,IAAI,OAAOG,KAAK,KAAK,QAAQ,EAAE;MAC7BH,KAAK,GAAGG,KAAK;IACf,CAAC,MACC,QAAQA,KAAK;MACX,KAAK,CAAC,CAAC;QAAE;UACPH,KAAK,GAAG,IAAI;UACZ;QACF;MACA,KAAK,CAAC,CAAC;QAAE;UACPA,KAAK,GAAG,IAAI;UACZ;QACF;MACA,KAAK,CAAC,CAAC;QAAE;UACPA,KAAK,GAAG,IAAI,GAAG,IAAI;UACnB;QACF;MACA,KAAK,CAAC,CAAC;QAAE;UACPA,KAAK,GAAGJ,UAAU,GAAG,GAAG,GAAG,IAAI;UAC/B;QACF;MACA,KAAK,CAAC,CAAC;QAAE;UACP,IAAI,CAACA,UAAU,IAAIgE,KAAK,EAAE;UAC1B5D,KAAK,GAAG,GAAG;UACX;QACF;MACA;QAAS;UACP;UACAA,KAAK,GAAG6D,MAAM,CAACC,YAAY,CAAC3D,KAAK,CAAC;QACpC;IACF;IACFyD,KAAK,GAAGzD,KAAK,KAAK,CAAC,CAAC;IACpBwD,MAAM,CAAChH,IAAI,CAACqD,KAAK,CAAC;EACpB;EACA,OAAO2D,MAAM,CAACI,IAAI,CAAC,EAAE,CAAC;AACxB"},"metadata":{},"sourceType":"module","externalDependencies":[]}