{"ast":null,"code":"import _objectSpread from \"/Users/abel/Documents/Code-Experiments/cool-storage-api/frontend/node_modules/@babel/runtime/helpers/esm/objectSpread2.js\";\n/**\n * @typedef {import('hast').Comment} Comment\n * @typedef {import('hast').Doctype} Doctype\n * @typedef {import('hast').Element} Element\n * @typedef {import('hast').Nodes} Nodes\n * @typedef {import('hast').Root} Root\n * @typedef {import('hast').RootContent} RootContent\n * @typedef {import('hast').Text} Text\n *\n * @typedef {import('mdast-util-to-hast').Raw} Raw\n *\n * @typedef {import('parse5').DefaultTreeAdapterMap} DefaultTreeAdapterMap\n * @typedef {import('parse5').ParserOptions<DefaultTreeAdapterMap>} ParserOptions\n * @typedef {import('parse5').Token.CharacterToken} CharacterToken\n * @typedef {import('parse5').Token.CommentToken} CommentToken\n * @typedef {import('parse5').Token.DoctypeToken} DoctypeToken\n * @typedef {import('parse5').Token.Location} Location\n * @typedef {import('parse5').Token.TagToken} TagToken\n *\n * @typedef {import('unist').Point} Point\n *\n * @typedef {import('vfile').VFile} VFile\n */\n\n/**\n * @typedef Options\n *   Configuration.\n * @property {VFile | null | undefined} [file]\n *   Corresponding virtual file representing the input document (optional).\n * @property {Array<Nodes['type']> | null | undefined} [passThrough]\n *   List of custom hast node types to pass through (as in, keep) (optional).\n *\n *   If the passed through nodes have children, those children are expected to\n *   be hast again and will be handled.\n *\n * @typedef State\n *   Info passed around about the current state.\n * @property {(node: Nodes) => undefined} handle\n *   Add a hast node to the parser.\n * @property {Options} options\n *   User configuration.\n * @property {Parser<DefaultTreeAdapterMap>} parser\n *   Current parser.\n * @property {boolean} stitches\n *   Whether there are stitches.\n *\n * @typedef {{type: 'comment', value: {stitch: Nodes}}} Stitch\n *   Custom comment-like value we pass through parse5, which contains a\n *   replacement node that we’ll swap back in afterwards.\n */\n\nimport structuredClone from '@ungap/structured-clone';\nimport { fromParse5 } from 'hast-util-from-parse5';\nimport { toParse5 } from 'hast-util-to-parse5';\nimport { htmlVoidElements } from 'html-void-elements';\nimport { Parser, Token, TokenizerMode, html } from 'parse5';\nimport { pointEnd, pointStart } from 'unist-util-position';\nimport { visit } from 'unist-util-visit';\nimport { webNamespaces } from 'web-namespaces';\nimport { zwitch } from 'zwitch';\n\n// Node types associated with MDX.\n// <https://github.com/mdx-js/mdx/blob/8a56312/packages/mdx/lib/node-types.js>\nvar knownMdxNames = new Set(['mdxFlowExpression', 'mdxJsxFlowElement', 'mdxJsxTextElement', 'mdxTextExpression', 'mdxjsEsm']);\n\n/** @type {ParserOptions} */\nvar parseOptions = {\n  sourceCodeLocationInfo: true,\n  scriptingEnabled: false\n};\n\n/**\n * Pass a hast tree through an HTML parser, which will fix nesting, and turn\n * raw nodes into actual nodes.\n *\n * @param {Nodes} tree\n *   Original hast tree to transform.\n * @param {Options | null | undefined} [options]\n *   Configuration (optional).\n * @returns {Nodes}\n *   Parsed again tree.\n */\nexport function raw(tree, options) {\n  var document = documentMode(tree);\n  /** @type {(node: Nodes, state: State) => undefined} */\n  var one = zwitch('type', {\n    handlers: {\n      root: root,\n      element: element,\n      text: text,\n      comment: comment,\n      doctype: doctype,\n      raw: handleRaw\n    },\n    unknown: unknown\n  });\n\n  /** @type {State} */\n  var state = {\n    parser: document ? new Parser(parseOptions) : Parser.getFragmentParser(undefined, parseOptions),\n    handle: function handle(node) {\n      one(node, state);\n    },\n    stitches: false,\n    options: options || {}\n  };\n  one(tree, state);\n  resetTokenizer(state, pointStart());\n  var p5 = document ? state.parser.document : state.parser.getFragment();\n  var result = fromParse5(p5, {\n    // To do: support `space`?\n    file: state.options.file\n  });\n  if (state.stitches) {\n    visit(result, 'comment', function (node, index, parent) {\n      var stitch = /** @type {Stitch} */ /** @type {unknown} */node;\n      if (stitch.value.stitch && parent && index !== undefined) {\n        /** @type {Array<RootContent>} */\n        var siblings = parent.children;\n        // @ts-expect-error: assume the stitch is allowed.\n        siblings[index] = stitch.value.stitch;\n        return index;\n      }\n    });\n  }\n\n  // Unpack if possible and when not given a `root`.\n  if (result.type === 'root' && result.children.length === 1 && result.children[0].type === tree.type) {\n    return result.children[0];\n  }\n  return result;\n}\n\n/**\n * Transform all nodes\n *\n * @param {Array<RootContent>} nodes\n *   hast content.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction all(nodes, state) {\n  var index = -1;\n\n  /* istanbul ignore else - invalid nodes, see rehypejs/rehype-raw#7. */\n  if (nodes) {\n    while (++index < nodes.length) {\n      state.handle(nodes[index]);\n    }\n  }\n}\n\n/**\n * Transform a root.\n *\n * @param {Root} node\n *   hast root node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction root(node, state) {\n  all(node.children, state);\n}\n\n/**\n * Transform an element.\n *\n * @param {Element} node\n *   hast element node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction element(node, state) {\n  startTag(node, state);\n  all(node.children, state);\n  endTag(node, state);\n}\n\n/**\n * Transform a text.\n *\n * @param {Text} node\n *   hast text node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction text(node, state) {\n  /** @type {CharacterToken} */\n  var token = {\n    type: Token.TokenType.CHARACTER,\n    chars: node.value,\n    location: createParse5Location(node)\n  };\n  resetTokenizer(state, pointStart(node));\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.currentToken = token;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser._processToken(state.parser.currentToken);\n}\n\n/**\n * Transform a doctype.\n *\n * @param {Doctype} node\n *   hast doctype node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction doctype(node, state) {\n  /** @type {DoctypeToken} */\n  var token = {\n    type: Token.TokenType.DOCTYPE,\n    name: 'html',\n    forceQuirks: false,\n    publicId: '',\n    systemId: '',\n    location: createParse5Location(node)\n  };\n  resetTokenizer(state, pointStart(node));\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.currentToken = token;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser._processToken(state.parser.currentToken);\n}\n\n/**\n * Transform a stitch.\n *\n * @param {Nodes} node\n *   unknown node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction stitch(node, state) {\n  // Mark that there are stitches, so we need to walk the tree and revert them.\n  state.stitches = true;\n\n  /** @type {Nodes} */\n  var clone = cloneWithoutChildren(node);\n\n  // Recurse, because to somewhat handle `[<x>]</x>` (where `[]` denotes the\n  // passed through node).\n  if ('children' in node && 'children' in clone) {\n    // Root in root out.\n    var fakeRoot = /** @type {Root} */\n    raw({\n      type: 'root',\n      children: node.children\n    }, state.options);\n    clone.children = fakeRoot.children;\n  }\n\n  // Hack: `value` is supposed to be a string, but as none of the tools\n  // (`parse5` or `hast-util-from-parse5`) looks at it, we can pass nodes\n  // through.\n  comment({\n    type: 'comment',\n    value: {\n      stitch: clone\n    }\n  }, state);\n}\n\n/**\n * Transform a comment (or stitch).\n *\n * @param {Comment | Stitch} node\n *   hast comment node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction comment(node, state) {\n  /** @type {string} */\n  // @ts-expect-error: we pass stitches through.\n  var data = node.value;\n\n  /** @type {CommentToken} */\n  var token = {\n    type: Token.TokenType.COMMENT,\n    data: data,\n    location: createParse5Location(node)\n  };\n  resetTokenizer(state, pointStart(node));\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.currentToken = token;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser._processToken(state.parser.currentToken);\n}\n\n/**\n * Transform a raw node.\n *\n * @param {Raw} node\n *   hast raw node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction handleRaw(node, state) {\n  // Reset preprocessor:\n  // See: <https://github.com/inikulin/parse5/blob/6f7ca60/packages/parse5/lib/tokenizer/preprocessor.ts#L18-L31>.\n  state.parser.tokenizer.preprocessor.html = '';\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.pos = -1;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.lastGapPos = -2;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.gapStack = [];\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.skipNextNewLine = false;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.lastChunkWritten = false;\n  state.parser.tokenizer.preprocessor.endOfChunkHit = false;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.isEol = false;\n\n  // Now pass `node.value`.\n  setPoint(state, pointStart(node));\n  state.parser.tokenizer.write(node.value, false);\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer._runParsingLoop();\n\n  // Character references hang, so if we ended there, we need to flush\n  // those too.\n  // We reset the preprocessor as if the document ends here.\n  // Then one single call to the relevant state does the trick, parse5\n  // consumes the whole token.\n\n  // Note: `State` is not exposed by `parse5`, so these numbers are fragile.\n  // See: <https://github.com/inikulin/parse5/blob/46cba43/packages/parse5/lib/tokenizer/index.ts#L58>\n  // Note: a change to `parse5`, which breaks this, was merged but not released.\n  // Investigate when it is.\n  if (state.parser.tokenizer.state === 72 /* NAMED_CHARACTER_REFERENCE */ || state.parser.tokenizer.state === 78 /* NUMERIC_CHARACTER_REFERENCE_END */) {\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.tokenizer.preprocessor.lastChunkWritten = true;\n    /** @type {number} */\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    var cp = state.parser.tokenizer._consume();\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.tokenizer._callState(cp);\n  }\n}\n\n/**\n * Crash on an unknown node.\n *\n * @param {unknown} node_\n *   unknown node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Never.\n */\nfunction unknown(node_, state) {\n  var node = /** @type {Nodes} */node_;\n  if (state.options.passThrough && state.options.passThrough.includes(node.type)) {\n    stitch(node, state);\n  } else {\n    var extra = '';\n    if (knownMdxNames.has(node.type)) {\n      extra = \". It looks like you are using MDX nodes with `hast-util-raw` (or `rehype-raw`). If you use this because you are using remark or rehype plugins that inject `'html'` nodes, then please raise an issue with that plugin, as its a bad and slow idea. If you use this because you are using markdown syntax, then you have to configure this utility (or plugin) to pass through these nodes (see `passThrough` in docs), but you can also migrate to use the MDX syntax\";\n    }\n    throw new Error('Cannot compile `' + node.type + '` node' + extra);\n  }\n}\n\n/**\n * Reset the tokenizer of a parser.\n *\n * @param {State} state\n *   Info passed around about the current state.\n * @param {Point | undefined} point\n *   Point.\n * @returns {undefined}\n *   Nothing.\n */\nfunction resetTokenizer(state, point) {\n  setPoint(state, point);\n\n  // Process final characters if they’re still there after hibernating.\n  /** @type {CharacterToken} */\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  var token = state.parser.tokenizer.currentCharacterToken;\n  if (token && token.location) {\n    token.location.endLine = state.parser.tokenizer.preprocessor.line;\n    token.location.endCol = state.parser.tokenizer.preprocessor.col + 1;\n    token.location.endOffset = state.parser.tokenizer.preprocessor.offset + 1;\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.currentToken = token;\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser._processToken(state.parser.currentToken);\n  }\n\n  // Reset tokenizer:\n  // See: <https://github.com/inikulin/parse5/blob/6f7ca60/packages/parse5/lib/tokenizer/index.ts#L187-L223>.\n  // Especially putting it back in the `data` state is useful: some elements,\n  // like textareas and iframes, change the state.\n  // See GH-7.\n  // But also if broken HTML is in `raw`, and then a correct element is given.\n  // See GH-11.\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.paused = false;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.inLoop = false;\n\n  // Note: don’t reset `state`, `inForeignNode`, or `lastStartTagName`, we\n  // manually update those when needed.\n  state.parser.tokenizer.active = false;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.returnState = TokenizerMode.DATA;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.charRefCode = -1;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.consumedAfterSnapshot = -1;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.currentLocation = null;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.currentCharacterToken = null;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.currentToken = null;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.currentAttr = {\n    name: '',\n    value: ''\n  };\n}\n\n/**\n * Set current location.\n *\n * @param {State} state\n *   Info passed around about the current state.\n * @param {Point | undefined} point\n *   Point.\n * @returns {undefined}\n *   Nothing.\n */\nfunction setPoint(state, point) {\n  if (point && point.offset !== undefined) {\n    /** @type {Location} */\n    var location = {\n      startLine: point.line,\n      startCol: point.column,\n      startOffset: point.offset,\n      endLine: -1,\n      endCol: -1,\n      endOffset: -1\n    };\n\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.tokenizer.preprocessor.lineStartPos = -point.column + 1; // Looks weird, but ensures we get correct positional info.\n    state.parser.tokenizer.preprocessor.droppedBufferSize = point.offset;\n    state.parser.tokenizer.preprocessor.line = point.line;\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.tokenizer.currentLocation = location;\n  }\n}\n\n/**\n * Emit a start tag.\n *\n * @param {Element} node\n *   Element.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction startTag(node, state) {\n  // Ignore tags if we’re in plain text.\n  if (state.parser.tokenizer.state === TokenizerMode.PLAINTEXT) return;\n  resetTokenizer(state, pointStart(node));\n  var current = state.parser.openElements.current;\n  var ns = 'namespaceURI' in current ? current.namespaceURI : webNamespaces.html;\n  if (ns === webNamespaces.html && node.tagName === 'svg') {\n    ns = webNamespaces.svg;\n  }\n  var result = toParse5( // Shallow clone to not delve into `children`: we only need the attributes.\n  _objectSpread(_objectSpread({}, node), {}, {\n    children: []\n  }), {\n    space: ns === webNamespaces.svg ? 'svg' : 'html'\n  });\n  // Always element.\n  /* c8 ignore next */\n  var attrs = 'attrs' in result ? result.attrs : [];\n\n  /** @type {TagToken} */\n  var tag = {\n    type: Token.TokenType.START_TAG,\n    tagName: node.tagName,\n    tagID: html.getTagID(node.tagName),\n    // We always send start and end tags.\n    selfClosing: false,\n    ackSelfClosing: false,\n    attrs: attrs,\n    location: createParse5Location(node)\n  };\n\n  // The HTML parsing algorithm works by doing half of the state management in\n  // the tokenizer and half in the parser.\n  // We can’t use the tokenizer here, as we don’t have strings.\n  // So we act *as if* the tokenizer emits tokens:\n\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.currentToken = tag;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser._processToken(state.parser.currentToken);\n\n  // …but then we still need a bunch of work that the tokenizer would normally\n  // do, such as:\n\n  // Set a tag name, similar to how the tokenizer would do it.\n  state.parser.tokenizer.lastStartTagName = node.tagName;\n\n  // `inForeignNode` is correctly set by the parser.\n}\n\n/**\n * Emit an end tag.\n *\n * @param {Element} node\n *   Element.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction endTag(node, state) {\n  // Do not emit closing tags for HTML void elements.\n  if (!state.parser.tokenizer.inForeignNode && htmlVoidElements.includes(node.tagName)) {\n    return;\n  }\n\n  // Ignore tags if we’re in plain text.\n  if (state.parser.tokenizer.state === TokenizerMode.PLAINTEXT) return;\n  resetTokenizer(state, pointEnd(node));\n\n  /** @type {TagToken} */\n  var tag = {\n    type: Token.TokenType.END_TAG,\n    tagName: node.tagName,\n    tagID: html.getTagID(node.tagName),\n    selfClosing: false,\n    ackSelfClosing: false,\n    attrs: [],\n    location: createParse5Location(node)\n  };\n\n  // The HTML parsing algorithm works by doing half of the state management in\n  // the tokenizer and half in the parser.\n  // We can’t use the tokenizer here, as we don’t have strings.\n  // So we act *as if* the tokenizer emits tokens:\n\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.currentToken = tag;\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser._processToken(state.parser.currentToken);\n\n  // …but then we still need a bunch of work that the tokenizer would normally\n  // do, such as:\n\n  // Switch back to the data state after alternative states that don’t accept\n  // tags:\n  if (\n  // Current element is closed.\n  tag.tagName === state.parser.tokenizer.lastStartTagName && (\n  // `<textarea>` and `<title>`\n  state.parser.tokenizer.state === TokenizerMode.RCDATA ||\n  // `<iframe>`, `<noembed>`, `<style>`, `<xmp>`\n  state.parser.tokenizer.state === TokenizerMode.RAWTEXT ||\n  // `<script>`\n  state.parser.tokenizer.state === TokenizerMode.SCRIPT_DATA)) {\n    state.parser.tokenizer.state = TokenizerMode.DATA;\n  }\n}\n\n/**\n * Check if `node` represents a whole document or a fragment.\n *\n * @param {Nodes} node\n *   hast node.\n * @returns {boolean}\n *   Whether this represents a whole document or a fragment.\n */\nfunction documentMode(node) {\n  var head = node.type === 'root' ? node.children[0] : node;\n  return Boolean(head && (head.type === 'doctype' || head.type === 'element' && head.tagName === 'html'));\n}\n\n/**\n * Get a `parse5` location from a node.\n *\n * @param {Nodes | Stitch} node\n *   hast node.\n * @returns {Location}\n *   `parse5` location.\n */\nfunction createParse5Location(node) {\n  var start = pointStart(node) || {\n    line: undefined,\n    column: undefined,\n    offset: undefined\n  };\n  var end = pointEnd(node) || {\n    line: undefined,\n    column: undefined,\n    offset: undefined\n  };\n\n  /** @type {Record<keyof Location, number | undefined>} */\n  var location = {\n    startLine: start.line,\n    startCol: start.column,\n    startOffset: start.offset,\n    endLine: end.line,\n    endCol: end.column,\n    endOffset: end.offset\n  };\n\n  // @ts-expect-error: unist point values can be `undefined` in hast, which\n  // `parse5` types don’t want.\n  return location;\n}\n\n/**\n * @template {Nodes} NodeType\n *   Node type.\n * @param {NodeType} node\n *   Node to clone.\n * @returns {NodeType}\n *   Cloned node, without children.\n */\nfunction cloneWithoutChildren(node) {\n  return 'children' in node ? structuredClone(_objectSpread(_objectSpread({}, node), {}, {\n    children: []\n  })) : structuredClone(node);\n}","map":{"version":3,"names":["structuredClone","fromParse5","toParse5","htmlVoidElements","Parser","Token","TokenizerMode","html","pointEnd","pointStart","visit","webNamespaces","zwitch","knownMdxNames","Set","parseOptions","sourceCodeLocationInfo","scriptingEnabled","raw","tree","options","document","documentMode","one","handlers","root","element","text","comment","doctype","handleRaw","unknown","state","parser","getFragmentParser","undefined","handle","node","stitches","resetTokenizer","p5","getFragment","result","file","index","parent","stitch","value","siblings","children","type","length","all","nodes","startTag","endTag","token","TokenType","CHARACTER","chars","location","createParse5Location","currentToken","_processToken","DOCTYPE","name","forceQuirks","publicId","systemId","clone","cloneWithoutChildren","fakeRoot","data","COMMENT","tokenizer","preprocessor","pos","lastGapPos","gapStack","skipNextNewLine","lastChunkWritten","endOfChunkHit","isEol","setPoint","write","_runParsingLoop","cp","_consume","_callState","node_","passThrough","includes","extra","has","Error","point","currentCharacterToken","endLine","line","endCol","col","endOffset","offset","paused","inLoop","active","returnState","DATA","charRefCode","consumedAfterSnapshot","currentLocation","currentAttr","startLine","startCol","column","startOffset","lineStartPos","droppedBufferSize","PLAINTEXT","current","openElements","ns","namespaceURI","tagName","svg","_objectSpread","space","attrs","tag","START_TAG","tagID","getTagID","selfClosing","ackSelfClosing","lastStartTagName","inForeignNode","END_TAG","RCDATA","RAWTEXT","SCRIPT_DATA","head","Boolean","start","end"],"sources":["/Users/abel/Documents/Code-Experiments/cool-storage-api/frontend/node_modules/hast-util-raw/lib/index.js"],"sourcesContent":["/**\n * @typedef {import('hast').Comment} Comment\n * @typedef {import('hast').Doctype} Doctype\n * @typedef {import('hast').Element} Element\n * @typedef {import('hast').Nodes} Nodes\n * @typedef {import('hast').Root} Root\n * @typedef {import('hast').RootContent} RootContent\n * @typedef {import('hast').Text} Text\n *\n * @typedef {import('mdast-util-to-hast').Raw} Raw\n *\n * @typedef {import('parse5').DefaultTreeAdapterMap} DefaultTreeAdapterMap\n * @typedef {import('parse5').ParserOptions<DefaultTreeAdapterMap>} ParserOptions\n * @typedef {import('parse5').Token.CharacterToken} CharacterToken\n * @typedef {import('parse5').Token.CommentToken} CommentToken\n * @typedef {import('parse5').Token.DoctypeToken} DoctypeToken\n * @typedef {import('parse5').Token.Location} Location\n * @typedef {import('parse5').Token.TagToken} TagToken\n *\n * @typedef {import('unist').Point} Point\n *\n * @typedef {import('vfile').VFile} VFile\n */\n\n/**\n * @typedef Options\n *   Configuration.\n * @property {VFile | null | undefined} [file]\n *   Corresponding virtual file representing the input document (optional).\n * @property {Array<Nodes['type']> | null | undefined} [passThrough]\n *   List of custom hast node types to pass through (as in, keep) (optional).\n *\n *   If the passed through nodes have children, those children are expected to\n *   be hast again and will be handled.\n *\n * @typedef State\n *   Info passed around about the current state.\n * @property {(node: Nodes) => undefined} handle\n *   Add a hast node to the parser.\n * @property {Options} options\n *   User configuration.\n * @property {Parser<DefaultTreeAdapterMap>} parser\n *   Current parser.\n * @property {boolean} stitches\n *   Whether there are stitches.\n *\n * @typedef {{type: 'comment', value: {stitch: Nodes}}} Stitch\n *   Custom comment-like value we pass through parse5, which contains a\n *   replacement node that we’ll swap back in afterwards.\n */\n\nimport structuredClone from '@ungap/structured-clone'\nimport {fromParse5} from 'hast-util-from-parse5'\nimport {toParse5} from 'hast-util-to-parse5'\nimport {htmlVoidElements} from 'html-void-elements'\nimport {Parser, Token, TokenizerMode, html} from 'parse5'\nimport {pointEnd, pointStart} from 'unist-util-position'\nimport {visit} from 'unist-util-visit'\nimport {webNamespaces} from 'web-namespaces'\nimport {zwitch} from 'zwitch'\n\n// Node types associated with MDX.\n// <https://github.com/mdx-js/mdx/blob/8a56312/packages/mdx/lib/node-types.js>\nconst knownMdxNames = new Set([\n  'mdxFlowExpression',\n  'mdxJsxFlowElement',\n  'mdxJsxTextElement',\n  'mdxTextExpression',\n  'mdxjsEsm'\n])\n\n/** @type {ParserOptions} */\nconst parseOptions = {sourceCodeLocationInfo: true, scriptingEnabled: false}\n\n/**\n * Pass a hast tree through an HTML parser, which will fix nesting, and turn\n * raw nodes into actual nodes.\n *\n * @param {Nodes} tree\n *   Original hast tree to transform.\n * @param {Options | null | undefined} [options]\n *   Configuration (optional).\n * @returns {Nodes}\n *   Parsed again tree.\n */\nexport function raw(tree, options) {\n  const document = documentMode(tree)\n  /** @type {(node: Nodes, state: State) => undefined} */\n  const one = zwitch('type', {\n    handlers: {root, element, text, comment, doctype, raw: handleRaw},\n    unknown\n  })\n\n  /** @type {State} */\n  const state = {\n    parser: document\n      ? new Parser(parseOptions)\n      : Parser.getFragmentParser(undefined, parseOptions),\n    handle(node) {\n      one(node, state)\n    },\n    stitches: false,\n    options: options || {}\n  }\n\n  one(tree, state)\n  resetTokenizer(state, pointStart())\n\n  const p5 = document ? state.parser.document : state.parser.getFragment()\n  const result = fromParse5(p5, {\n    // To do: support `space`?\n    file: state.options.file\n  })\n\n  if (state.stitches) {\n    visit(result, 'comment', function (node, index, parent) {\n      const stitch = /** @type {Stitch} */ (/** @type {unknown} */ (node))\n      if (stitch.value.stitch && parent && index !== undefined) {\n        /** @type {Array<RootContent>} */\n        const siblings = parent.children\n        // @ts-expect-error: assume the stitch is allowed.\n        siblings[index] = stitch.value.stitch\n        return index\n      }\n    })\n  }\n\n  // Unpack if possible and when not given a `root`.\n  if (\n    result.type === 'root' &&\n    result.children.length === 1 &&\n    result.children[0].type === tree.type\n  ) {\n    return result.children[0]\n  }\n\n  return result\n}\n\n/**\n * Transform all nodes\n *\n * @param {Array<RootContent>} nodes\n *   hast content.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction all(nodes, state) {\n  let index = -1\n\n  /* istanbul ignore else - invalid nodes, see rehypejs/rehype-raw#7. */\n  if (nodes) {\n    while (++index < nodes.length) {\n      state.handle(nodes[index])\n    }\n  }\n}\n\n/**\n * Transform a root.\n *\n * @param {Root} node\n *   hast root node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction root(node, state) {\n  all(node.children, state)\n}\n\n/**\n * Transform an element.\n *\n * @param {Element} node\n *   hast element node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction element(node, state) {\n  startTag(node, state)\n\n  all(node.children, state)\n\n  endTag(node, state)\n}\n\n/**\n * Transform a text.\n *\n * @param {Text} node\n *   hast text node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction text(node, state) {\n  /** @type {CharacterToken} */\n  const token = {\n    type: Token.TokenType.CHARACTER,\n    chars: node.value,\n    location: createParse5Location(node)\n  }\n\n  resetTokenizer(state, pointStart(node))\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.currentToken = token\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser._processToken(state.parser.currentToken)\n}\n\n/**\n * Transform a doctype.\n *\n * @param {Doctype} node\n *   hast doctype node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction doctype(node, state) {\n  /** @type {DoctypeToken} */\n  const token = {\n    type: Token.TokenType.DOCTYPE,\n    name: 'html',\n    forceQuirks: false,\n    publicId: '',\n    systemId: '',\n    location: createParse5Location(node)\n  }\n\n  resetTokenizer(state, pointStart(node))\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.currentToken = token\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser._processToken(state.parser.currentToken)\n}\n\n/**\n * Transform a stitch.\n *\n * @param {Nodes} node\n *   unknown node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction stitch(node, state) {\n  // Mark that there are stitches, so we need to walk the tree and revert them.\n  state.stitches = true\n\n  /** @type {Nodes} */\n  const clone = cloneWithoutChildren(node)\n\n  // Recurse, because to somewhat handle `[<x>]</x>` (where `[]` denotes the\n  // passed through node).\n  if ('children' in node && 'children' in clone) {\n    // Root in root out.\n    const fakeRoot = /** @type {Root} */ (\n      raw({type: 'root', children: node.children}, state.options)\n    )\n    clone.children = fakeRoot.children\n  }\n\n  // Hack: `value` is supposed to be a string, but as none of the tools\n  // (`parse5` or `hast-util-from-parse5`) looks at it, we can pass nodes\n  // through.\n  comment({type: 'comment', value: {stitch: clone}}, state)\n}\n\n/**\n * Transform a comment (or stitch).\n *\n * @param {Comment | Stitch} node\n *   hast comment node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction comment(node, state) {\n  /** @type {string} */\n  // @ts-expect-error: we pass stitches through.\n  const data = node.value\n\n  /** @type {CommentToken} */\n  const token = {\n    type: Token.TokenType.COMMENT,\n    data,\n    location: createParse5Location(node)\n  }\n  resetTokenizer(state, pointStart(node))\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.currentToken = token\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser._processToken(state.parser.currentToken)\n}\n\n/**\n * Transform a raw node.\n *\n * @param {Raw} node\n *   hast raw node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction handleRaw(node, state) {\n  // Reset preprocessor:\n  // See: <https://github.com/inikulin/parse5/blob/6f7ca60/packages/parse5/lib/tokenizer/preprocessor.ts#L18-L31>.\n  state.parser.tokenizer.preprocessor.html = ''\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.pos = -1\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.lastGapPos = -2\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.gapStack = []\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.skipNextNewLine = false\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.lastChunkWritten = false\n  state.parser.tokenizer.preprocessor.endOfChunkHit = false\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.preprocessor.isEol = false\n\n  // Now pass `node.value`.\n  setPoint(state, pointStart(node))\n  state.parser.tokenizer.write(node.value, false)\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer._runParsingLoop()\n\n  // Character references hang, so if we ended there, we need to flush\n  // those too.\n  // We reset the preprocessor as if the document ends here.\n  // Then one single call to the relevant state does the trick, parse5\n  // consumes the whole token.\n\n  // Note: `State` is not exposed by `parse5`, so these numbers are fragile.\n  // See: <https://github.com/inikulin/parse5/blob/46cba43/packages/parse5/lib/tokenizer/index.ts#L58>\n  // Note: a change to `parse5`, which breaks this, was merged but not released.\n  // Investigate when it is.\n  if (\n    state.parser.tokenizer.state === 72 /* NAMED_CHARACTER_REFERENCE */ ||\n    state.parser.tokenizer.state === 78 /* NUMERIC_CHARACTER_REFERENCE_END */\n  ) {\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.tokenizer.preprocessor.lastChunkWritten = true\n    /** @type {number} */\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    const cp = state.parser.tokenizer._consume()\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.tokenizer._callState(cp)\n  }\n}\n\n/**\n * Crash on an unknown node.\n *\n * @param {unknown} node_\n *   unknown node.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Never.\n */\nfunction unknown(node_, state) {\n  const node = /** @type {Nodes} */ (node_)\n\n  if (\n    state.options.passThrough &&\n    state.options.passThrough.includes(node.type)\n  ) {\n    stitch(node, state)\n  } else {\n    let extra = ''\n\n    if (knownMdxNames.has(node.type)) {\n      extra =\n        \". It looks like you are using MDX nodes with `hast-util-raw` (or `rehype-raw`). If you use this because you are using remark or rehype plugins that inject `'html'` nodes, then please raise an issue with that plugin, as its a bad and slow idea. If you use this because you are using markdown syntax, then you have to configure this utility (or plugin) to pass through these nodes (see `passThrough` in docs), but you can also migrate to use the MDX syntax\"\n    }\n\n    throw new Error('Cannot compile `' + node.type + '` node' + extra)\n  }\n}\n\n/**\n * Reset the tokenizer of a parser.\n *\n * @param {State} state\n *   Info passed around about the current state.\n * @param {Point | undefined} point\n *   Point.\n * @returns {undefined}\n *   Nothing.\n */\nfunction resetTokenizer(state, point) {\n  setPoint(state, point)\n\n  // Process final characters if they’re still there after hibernating.\n  /** @type {CharacterToken} */\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  const token = state.parser.tokenizer.currentCharacterToken\n\n  if (token && token.location) {\n    token.location.endLine = state.parser.tokenizer.preprocessor.line\n    token.location.endCol = state.parser.tokenizer.preprocessor.col + 1\n    token.location.endOffset = state.parser.tokenizer.preprocessor.offset + 1\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.currentToken = token\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser._processToken(state.parser.currentToken)\n  }\n\n  // Reset tokenizer:\n  // See: <https://github.com/inikulin/parse5/blob/6f7ca60/packages/parse5/lib/tokenizer/index.ts#L187-L223>.\n  // Especially putting it back in the `data` state is useful: some elements,\n  // like textareas and iframes, change the state.\n  // See GH-7.\n  // But also if broken HTML is in `raw`, and then a correct element is given.\n  // See GH-11.\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.paused = false\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.inLoop = false\n\n  // Note: don’t reset `state`, `inForeignNode`, or `lastStartTagName`, we\n  // manually update those when needed.\n  state.parser.tokenizer.active = false\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.returnState = TokenizerMode.DATA\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.charRefCode = -1\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.consumedAfterSnapshot = -1\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.currentLocation = null\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.currentCharacterToken = null\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.currentToken = null\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.tokenizer.currentAttr = {name: '', value: ''}\n}\n\n/**\n * Set current location.\n *\n * @param {State} state\n *   Info passed around about the current state.\n * @param {Point | undefined} point\n *   Point.\n * @returns {undefined}\n *   Nothing.\n */\nfunction setPoint(state, point) {\n  if (point && point.offset !== undefined) {\n    /** @type {Location} */\n    const location = {\n      startLine: point.line,\n      startCol: point.column,\n      startOffset: point.offset,\n      endLine: -1,\n      endCol: -1,\n      endOffset: -1\n    }\n\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.tokenizer.preprocessor.lineStartPos = -point.column + 1 // Looks weird, but ensures we get correct positional info.\n    state.parser.tokenizer.preprocessor.droppedBufferSize = point.offset\n    state.parser.tokenizer.preprocessor.line = point.line\n    // @ts-expect-error: private.\n    // type-coverage:ignore-next-line\n    state.parser.tokenizer.currentLocation = location\n  }\n}\n\n/**\n * Emit a start tag.\n *\n * @param {Element} node\n *   Element.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction startTag(node, state) {\n  // Ignore tags if we’re in plain text.\n  if (state.parser.tokenizer.state === TokenizerMode.PLAINTEXT) return\n\n  resetTokenizer(state, pointStart(node))\n\n  const current = state.parser.openElements.current\n  let ns = 'namespaceURI' in current ? current.namespaceURI : webNamespaces.html\n\n  if (ns === webNamespaces.html && node.tagName === 'svg') {\n    ns = webNamespaces.svg\n  }\n\n  const result = toParse5(\n    // Shallow clone to not delve into `children`: we only need the attributes.\n    {...node, children: []},\n    {space: ns === webNamespaces.svg ? 'svg' : 'html'}\n  )\n  // Always element.\n  /* c8 ignore next */\n  const attrs = 'attrs' in result ? result.attrs : []\n\n  /** @type {TagToken} */\n  const tag = {\n    type: Token.TokenType.START_TAG,\n    tagName: node.tagName,\n    tagID: html.getTagID(node.tagName),\n    // We always send start and end tags.\n    selfClosing: false,\n    ackSelfClosing: false,\n    attrs,\n    location: createParse5Location(node)\n  }\n\n  // The HTML parsing algorithm works by doing half of the state management in\n  // the tokenizer and half in the parser.\n  // We can’t use the tokenizer here, as we don’t have strings.\n  // So we act *as if* the tokenizer emits tokens:\n\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.currentToken = tag\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser._processToken(state.parser.currentToken)\n\n  // …but then we still need a bunch of work that the tokenizer would normally\n  // do, such as:\n\n  // Set a tag name, similar to how the tokenizer would do it.\n  state.parser.tokenizer.lastStartTagName = node.tagName\n\n  // `inForeignNode` is correctly set by the parser.\n}\n\n/**\n * Emit an end tag.\n *\n * @param {Element} node\n *   Element.\n * @param {State} state\n *   Info passed around about the current state.\n * @returns {undefined}\n *   Nothing.\n */\nfunction endTag(node, state) {\n  // Do not emit closing tags for HTML void elements.\n  if (\n    !state.parser.tokenizer.inForeignNode &&\n    htmlVoidElements.includes(node.tagName)\n  ) {\n    return\n  }\n\n  // Ignore tags if we’re in plain text.\n  if (state.parser.tokenizer.state === TokenizerMode.PLAINTEXT) return\n\n  resetTokenizer(state, pointEnd(node))\n\n  /** @type {TagToken} */\n  const tag = {\n    type: Token.TokenType.END_TAG,\n    tagName: node.tagName,\n    tagID: html.getTagID(node.tagName),\n    selfClosing: false,\n    ackSelfClosing: false,\n    attrs: [],\n    location: createParse5Location(node)\n  }\n\n  // The HTML parsing algorithm works by doing half of the state management in\n  // the tokenizer and half in the parser.\n  // We can’t use the tokenizer here, as we don’t have strings.\n  // So we act *as if* the tokenizer emits tokens:\n\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser.currentToken = tag\n  // @ts-expect-error: private.\n  // type-coverage:ignore-next-line\n  state.parser._processToken(state.parser.currentToken)\n\n  // …but then we still need a bunch of work that the tokenizer would normally\n  // do, such as:\n\n  // Switch back to the data state after alternative states that don’t accept\n  // tags:\n  if (\n    // Current element is closed.\n    tag.tagName === state.parser.tokenizer.lastStartTagName &&\n    // `<textarea>` and `<title>`\n    (state.parser.tokenizer.state === TokenizerMode.RCDATA ||\n      // `<iframe>`, `<noembed>`, `<style>`, `<xmp>`\n      state.parser.tokenizer.state === TokenizerMode.RAWTEXT ||\n      // `<script>`\n      state.parser.tokenizer.state === TokenizerMode.SCRIPT_DATA)\n  ) {\n    state.parser.tokenizer.state = TokenizerMode.DATA\n  }\n}\n\n/**\n * Check if `node` represents a whole document or a fragment.\n *\n * @param {Nodes} node\n *   hast node.\n * @returns {boolean}\n *   Whether this represents a whole document or a fragment.\n */\nfunction documentMode(node) {\n  const head = node.type === 'root' ? node.children[0] : node\n  return Boolean(\n    head &&\n      (head.type === 'doctype' ||\n        (head.type === 'element' && head.tagName === 'html'))\n  )\n}\n\n/**\n * Get a `parse5` location from a node.\n *\n * @param {Nodes | Stitch} node\n *   hast node.\n * @returns {Location}\n *   `parse5` location.\n */\nfunction createParse5Location(node) {\n  const start = pointStart(node) || {\n    line: undefined,\n    column: undefined,\n    offset: undefined\n  }\n  const end = pointEnd(node) || {\n    line: undefined,\n    column: undefined,\n    offset: undefined\n  }\n\n  /** @type {Record<keyof Location, number | undefined>} */\n  const location = {\n    startLine: start.line,\n    startCol: start.column,\n    startOffset: start.offset,\n    endLine: end.line,\n    endCol: end.column,\n    endOffset: end.offset\n  }\n\n  // @ts-expect-error: unist point values can be `undefined` in hast, which\n  // `parse5` types don’t want.\n  return location\n}\n\n/**\n * @template {Nodes} NodeType\n *   Node type.\n * @param {NodeType} node\n *   Node to clone.\n * @returns {NodeType}\n *   Cloned node, without children.\n */\nfunction cloneWithoutChildren(node) {\n  return 'children' in node\n    ? structuredClone({...node, children: []})\n    : structuredClone(node)\n}\n"],"mappings":";AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,OAAOA,eAAe,MAAM,yBAAyB;AACrD,SAAQC,UAAU,QAAO,uBAAuB;AAChD,SAAQC,QAAQ,QAAO,qBAAqB;AAC5C,SAAQC,gBAAgB,QAAO,oBAAoB;AACnD,SAAQC,MAAM,EAAEC,KAAK,EAAEC,aAAa,EAAEC,IAAI,QAAO,QAAQ;AACzD,SAAQC,QAAQ,EAAEC,UAAU,QAAO,qBAAqB;AACxD,SAAQC,KAAK,QAAO,kBAAkB;AACtC,SAAQC,aAAa,QAAO,gBAAgB;AAC5C,SAAQC,MAAM,QAAO,QAAQ;;AAE7B;AACA;AACA,IAAMC,aAAa,GAAG,IAAIC,GAAG,CAAC,CAC5B,mBAAmB,EACnB,mBAAmB,EACnB,mBAAmB,EACnB,mBAAmB,EACnB,UAAU,CACX,CAAC;;AAEF;AACA,IAAMC,YAAY,GAAG;EAACC,sBAAsB,EAAE,IAAI;EAAEC,gBAAgB,EAAE;AAAK,CAAC;;AAE5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,SAASC,GAAGA,CAACC,IAAI,EAAEC,OAAO,EAAE;EACjC,IAAMC,QAAQ,GAAGC,YAAY,CAACH,IAAI,CAAC;EACnC;EACA,IAAMI,GAAG,GAAGX,MAAM,CAAC,MAAM,EAAE;IACzBY,QAAQ,EAAE;MAACC,IAAI,EAAJA,IAAI;MAAEC,OAAO,EAAPA,OAAO;MAAEC,IAAI,EAAJA,IAAI;MAAEC,OAAO,EAAPA,OAAO;MAAEC,OAAO,EAAPA,OAAO;MAAEX,GAAG,EAAEY;IAAS,CAAC;IACjEC,OAAO,EAAPA;EACF,CAAC,CAAC;;EAEF;EACA,IAAMC,KAAK,GAAG;IACZC,MAAM,EAAEZ,QAAQ,GACZ,IAAIjB,MAAM,CAACW,YAAY,CAAC,GACxBX,MAAM,CAAC8B,iBAAiB,CAACC,SAAS,EAAEpB,YAAY,CAAC;IACrDqB,MAAM,WAAAA,OAACC,IAAI,EAAE;MACXd,GAAG,CAACc,IAAI,EAAEL,KAAK,CAAC;IAClB,CAAC;IACDM,QAAQ,EAAE,KAAK;IACflB,OAAO,EAAEA,OAAO,IAAI,CAAC;EACvB,CAAC;EAEDG,GAAG,CAACJ,IAAI,EAAEa,KAAK,CAAC;EAChBO,cAAc,CAACP,KAAK,EAAEvB,UAAU,CAAC,CAAC,CAAC;EAEnC,IAAM+B,EAAE,GAAGnB,QAAQ,GAAGW,KAAK,CAACC,MAAM,CAACZ,QAAQ,GAAGW,KAAK,CAACC,MAAM,CAACQ,WAAW,CAAC,CAAC;EACxE,IAAMC,MAAM,GAAGzC,UAAU,CAACuC,EAAE,EAAE;IAC5B;IACAG,IAAI,EAAEX,KAAK,CAACZ,OAAO,CAACuB;EACtB,CAAC,CAAC;EAEF,IAAIX,KAAK,CAACM,QAAQ,EAAE;IAClB5B,KAAK,CAACgC,MAAM,EAAE,SAAS,EAAE,UAAUL,IAAI,EAAEO,KAAK,EAAEC,MAAM,EAAE;MACtD,IAAMC,MAAM,GAAG,sBAAuB,sBAAwBT,IAAM;MACpE,IAAIS,MAAM,CAACC,KAAK,CAACD,MAAM,IAAID,MAAM,IAAID,KAAK,KAAKT,SAAS,EAAE;QACxD;QACA,IAAMa,QAAQ,GAAGH,MAAM,CAACI,QAAQ;QAChC;QACAD,QAAQ,CAACJ,KAAK,CAAC,GAAGE,MAAM,CAACC,KAAK,CAACD,MAAM;QACrC,OAAOF,KAAK;MACd;IACF,CAAC,CAAC;EACJ;;EAEA;EACA,IACEF,MAAM,CAACQ,IAAI,KAAK,MAAM,IACtBR,MAAM,CAACO,QAAQ,CAACE,MAAM,KAAK,CAAC,IAC5BT,MAAM,CAACO,QAAQ,CAAC,CAAC,CAAC,CAACC,IAAI,KAAK/B,IAAI,CAAC+B,IAAI,EACrC;IACA,OAAOR,MAAM,CAACO,QAAQ,CAAC,CAAC,CAAC;EAC3B;EAEA,OAAOP,MAAM;AACf;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASU,GAAGA,CAACC,KAAK,EAAErB,KAAK,EAAE;EACzB,IAAIY,KAAK,GAAG,CAAC,CAAC;;EAEd;EACA,IAAIS,KAAK,EAAE;IACT,OAAO,EAAET,KAAK,GAAGS,KAAK,CAACF,MAAM,EAAE;MAC7BnB,KAAK,CAACI,MAAM,CAACiB,KAAK,CAACT,KAAK,CAAC,CAAC;IAC5B;EACF;AACF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASnB,IAAIA,CAACY,IAAI,EAAEL,KAAK,EAAE;EACzBoB,GAAG,CAACf,IAAI,CAACY,QAAQ,EAAEjB,KAAK,CAAC;AAC3B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASN,OAAOA,CAACW,IAAI,EAAEL,KAAK,EAAE;EAC5BsB,QAAQ,CAACjB,IAAI,EAAEL,KAAK,CAAC;EAErBoB,GAAG,CAACf,IAAI,CAACY,QAAQ,EAAEjB,KAAK,CAAC;EAEzBuB,MAAM,CAAClB,IAAI,EAAEL,KAAK,CAAC;AACrB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASL,IAAIA,CAACU,IAAI,EAAEL,KAAK,EAAE;EACzB;EACA,IAAMwB,KAAK,GAAG;IACZN,IAAI,EAAE7C,KAAK,CAACoD,SAAS,CAACC,SAAS;IAC/BC,KAAK,EAAEtB,IAAI,CAACU,KAAK;IACjBa,QAAQ,EAAEC,oBAAoB,CAACxB,IAAI;EACrC,CAAC;EAEDE,cAAc,CAACP,KAAK,EAAEvB,UAAU,CAAC4B,IAAI,CAAC,CAAC;EACvC;EACA;EACAL,KAAK,CAACC,MAAM,CAAC6B,YAAY,GAAGN,KAAK;EACjC;EACA;EACAxB,KAAK,CAACC,MAAM,CAAC8B,aAAa,CAAC/B,KAAK,CAACC,MAAM,CAAC6B,YAAY,CAAC;AACvD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASjC,OAAOA,CAACQ,IAAI,EAAEL,KAAK,EAAE;EAC5B;EACA,IAAMwB,KAAK,GAAG;IACZN,IAAI,EAAE7C,KAAK,CAACoD,SAAS,CAACO,OAAO;IAC7BC,IAAI,EAAE,MAAM;IACZC,WAAW,EAAE,KAAK;IAClBC,QAAQ,EAAE,EAAE;IACZC,QAAQ,EAAE,EAAE;IACZR,QAAQ,EAAEC,oBAAoB,CAACxB,IAAI;EACrC,CAAC;EAEDE,cAAc,CAACP,KAAK,EAAEvB,UAAU,CAAC4B,IAAI,CAAC,CAAC;EACvC;EACA;EACAL,KAAK,CAACC,MAAM,CAAC6B,YAAY,GAAGN,KAAK;EACjC;EACA;EACAxB,KAAK,CAACC,MAAM,CAAC8B,aAAa,CAAC/B,KAAK,CAACC,MAAM,CAAC6B,YAAY,CAAC;AACvD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAShB,MAAMA,CAACT,IAAI,EAAEL,KAAK,EAAE;EAC3B;EACAA,KAAK,CAACM,QAAQ,GAAG,IAAI;;EAErB;EACA,IAAM+B,KAAK,GAAGC,oBAAoB,CAACjC,IAAI,CAAC;;EAExC;EACA;EACA,IAAI,UAAU,IAAIA,IAAI,IAAI,UAAU,IAAIgC,KAAK,EAAE;IAC7C;IACA,IAAME,QAAQ,GAAG;IACfrD,GAAG,CAAC;MAACgC,IAAI,EAAE,MAAM;MAAED,QAAQ,EAAEZ,IAAI,CAACY;IAAQ,CAAC,EAAEjB,KAAK,CAACZ,OAAO,CAC3D;IACDiD,KAAK,CAACpB,QAAQ,GAAGsB,QAAQ,CAACtB,QAAQ;EACpC;;EAEA;EACA;EACA;EACArB,OAAO,CAAC;IAACsB,IAAI,EAAE,SAAS;IAAEH,KAAK,EAAE;MAACD,MAAM,EAAEuB;IAAK;EAAC,CAAC,EAAErC,KAAK,CAAC;AAC3D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASJ,OAAOA,CAACS,IAAI,EAAEL,KAAK,EAAE;EAC5B;EACA;EACA,IAAMwC,IAAI,GAAGnC,IAAI,CAACU,KAAK;;EAEvB;EACA,IAAMS,KAAK,GAAG;IACZN,IAAI,EAAE7C,KAAK,CAACoD,SAAS,CAACgB,OAAO;IAC7BD,IAAI,EAAJA,IAAI;IACJZ,QAAQ,EAAEC,oBAAoB,CAACxB,IAAI;EACrC,CAAC;EACDE,cAAc,CAACP,KAAK,EAAEvB,UAAU,CAAC4B,IAAI,CAAC,CAAC;EACvC;EACA;EACAL,KAAK,CAACC,MAAM,CAAC6B,YAAY,GAAGN,KAAK;EACjC;EACA;EACAxB,KAAK,CAACC,MAAM,CAAC8B,aAAa,CAAC/B,KAAK,CAACC,MAAM,CAAC6B,YAAY,CAAC;AACvD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAShC,SAASA,CAACO,IAAI,EAAEL,KAAK,EAAE;EAC9B;EACA;EACAA,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACpE,IAAI,GAAG,EAAE;EAC7C;EACA;EACAyB,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACC,GAAG,GAAG,CAAC,CAAC;EAC5C;EACA;EACA5C,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACE,UAAU,GAAG,CAAC,CAAC;EACnD;EACA;EACA7C,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACG,QAAQ,GAAG,EAAE;EACjD;EACA;EACA9C,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACI,eAAe,GAAG,KAAK;EAC3D;EACA;EACA/C,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACK,gBAAgB,GAAG,KAAK;EAC5DhD,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACM,aAAa,GAAG,KAAK;EACzD;EACA;EACAjD,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACO,KAAK,GAAG,KAAK;;EAEjD;EACAC,QAAQ,CAACnD,KAAK,EAAEvB,UAAU,CAAC4B,IAAI,CAAC,CAAC;EACjCL,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACU,KAAK,CAAC/C,IAAI,CAACU,KAAK,EAAE,KAAK,CAAC;EAC/C;EACA;EACAf,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACW,eAAe,CAAC,CAAC;;EAExC;EACA;EACA;EACA;EACA;;EAEA;EACA;EACA;EACA;EACA,IACErD,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC1C,KAAK,KAAK,EAAE,CAAC,mCACpCA,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC1C,KAAK,KAAK,EAAE,CAAC,uCACpC;IACA;IACA;IACAA,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACK,gBAAgB,GAAG,IAAI;IAC3D;IACA;IACA;IACA,IAAMM,EAAE,GAAGtD,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACa,QAAQ,CAAC,CAAC;IAC5C;IACA;IACAvD,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACc,UAAU,CAACF,EAAE,CAAC;EACvC;AACF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASvD,OAAOA,CAAC0D,KAAK,EAAEzD,KAAK,EAAE;EAC7B,IAAMK,IAAI,GAAG,oBAAsBoD,KAAM;EAEzC,IACEzD,KAAK,CAACZ,OAAO,CAACsE,WAAW,IACzB1D,KAAK,CAACZ,OAAO,CAACsE,WAAW,CAACC,QAAQ,CAACtD,IAAI,CAACa,IAAI,CAAC,EAC7C;IACAJ,MAAM,CAACT,IAAI,EAAEL,KAAK,CAAC;EACrB,CAAC,MAAM;IACL,IAAI4D,KAAK,GAAG,EAAE;IAEd,IAAI/E,aAAa,CAACgF,GAAG,CAACxD,IAAI,CAACa,IAAI,CAAC,EAAE;MAChC0C,KAAK,GACH,wcAAwc;IAC5c;IAEA,MAAM,IAAIE,KAAK,CAAC,kBAAkB,GAAGzD,IAAI,CAACa,IAAI,GAAG,QAAQ,GAAG0C,KAAK,CAAC;EACpE;AACF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASrD,cAAcA,CAACP,KAAK,EAAE+D,KAAK,EAAE;EACpCZ,QAAQ,CAACnD,KAAK,EAAE+D,KAAK,CAAC;;EAEtB;EACA;EACA;EACA;EACA,IAAMvC,KAAK,GAAGxB,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACsB,qBAAqB;EAE1D,IAAIxC,KAAK,IAAIA,KAAK,CAACI,QAAQ,EAAE;IAC3BJ,KAAK,CAACI,QAAQ,CAACqC,OAAO,GAAGjE,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACuB,IAAI;IACjE1C,KAAK,CAACI,QAAQ,CAACuC,MAAM,GAAGnE,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACyB,GAAG,GAAG,CAAC;IACnE5C,KAAK,CAACI,QAAQ,CAACyC,SAAS,GAAGrE,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAAC2B,MAAM,GAAG,CAAC;IACzE;IACA;IACAtE,KAAK,CAACC,MAAM,CAAC6B,YAAY,GAAGN,KAAK;IACjC;IACA;IACAxB,KAAK,CAACC,MAAM,CAAC8B,aAAa,CAAC/B,KAAK,CAACC,MAAM,CAAC6B,YAAY,CAAC;EACvD;;EAEA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA9B,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC6B,MAAM,GAAG,KAAK;EACrC;EACA;EACAvE,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC8B,MAAM,GAAG,KAAK;;EAErC;EACA;EACAxE,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC+B,MAAM,GAAG,KAAK;EACrC;EACA;EACAzE,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACgC,WAAW,GAAGpG,aAAa,CAACqG,IAAI;EACvD;EACA;EACA3E,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACkC,WAAW,GAAG,CAAC,CAAC;EACvC;EACA;EACA5E,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACmC,qBAAqB,GAAG,CAAC,CAAC;EACjD;EACA;EACA7E,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACoC,eAAe,GAAG,IAAI;EAC7C;EACA;EACA9E,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACsB,qBAAqB,GAAG,IAAI;EACnD;EACA;EACAhE,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACZ,YAAY,GAAG,IAAI;EAC1C;EACA;EACA9B,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACqC,WAAW,GAAG;IAAC9C,IAAI,EAAE,EAAE;IAAElB,KAAK,EAAE;EAAE,CAAC;AAC5D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASoC,QAAQA,CAACnD,KAAK,EAAE+D,KAAK,EAAE;EAC9B,IAAIA,KAAK,IAAIA,KAAK,CAACO,MAAM,KAAKnE,SAAS,EAAE;IACvC;IACA,IAAMyB,QAAQ,GAAG;MACfoD,SAAS,EAAEjB,KAAK,CAACG,IAAI;MACrBe,QAAQ,EAAElB,KAAK,CAACmB,MAAM;MACtBC,WAAW,EAAEpB,KAAK,CAACO,MAAM;MACzBL,OAAO,EAAE,CAAC,CAAC;MACXE,MAAM,EAAE,CAAC,CAAC;MACVE,SAAS,EAAE,CAAC;IACd,CAAC;;IAED;IACA;IACArE,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACyC,YAAY,GAAG,CAACrB,KAAK,CAACmB,MAAM,GAAG,CAAC,EAAC;IACrElF,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAAC0C,iBAAiB,GAAGtB,KAAK,CAACO,MAAM;IACpEtE,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACC,YAAY,CAACuB,IAAI,GAAGH,KAAK,CAACG,IAAI;IACrD;IACA;IACAlE,KAAK,CAACC,MAAM,CAACyC,SAAS,CAACoC,eAAe,GAAGlD,QAAQ;EACnD;AACF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASN,QAAQA,CAACjB,IAAI,EAAEL,KAAK,EAAE;EAC7B;EACA,IAAIA,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC1C,KAAK,KAAK1B,aAAa,CAACgH,SAAS,EAAE;EAE9D/E,cAAc,CAACP,KAAK,EAAEvB,UAAU,CAAC4B,IAAI,CAAC,CAAC;EAEvC,IAAMkF,OAAO,GAAGvF,KAAK,CAACC,MAAM,CAACuF,YAAY,CAACD,OAAO;EACjD,IAAIE,EAAE,GAAG,cAAc,IAAIF,OAAO,GAAGA,OAAO,CAACG,YAAY,GAAG/G,aAAa,CAACJ,IAAI;EAE9E,IAAIkH,EAAE,KAAK9G,aAAa,CAACJ,IAAI,IAAI8B,IAAI,CAACsF,OAAO,KAAK,KAAK,EAAE;IACvDF,EAAE,GAAG9G,aAAa,CAACiH,GAAG;EACxB;EAEA,IAAMlF,MAAM,GAAGxC,QAAQ,EACrB;EAAA2H,aAAA,CAAAA,aAAA,KACIxF,IAAI;IAAEY,QAAQ,EAAE;EAAE,IACtB;IAAC6E,KAAK,EAAEL,EAAE,KAAK9G,aAAa,CAACiH,GAAG,GAAG,KAAK,GAAG;EAAM,CACnD,CAAC;EACD;EACA;EACA,IAAMG,KAAK,GAAG,OAAO,IAAIrF,MAAM,GAAGA,MAAM,CAACqF,KAAK,GAAG,EAAE;;EAEnD;EACA,IAAMC,GAAG,GAAG;IACV9E,IAAI,EAAE7C,KAAK,CAACoD,SAAS,CAACwE,SAAS;IAC/BN,OAAO,EAAEtF,IAAI,CAACsF,OAAO;IACrBO,KAAK,EAAE3H,IAAI,CAAC4H,QAAQ,CAAC9F,IAAI,CAACsF,OAAO,CAAC;IAClC;IACAS,WAAW,EAAE,KAAK;IAClBC,cAAc,EAAE,KAAK;IACrBN,KAAK,EAALA,KAAK;IACLnE,QAAQ,EAAEC,oBAAoB,CAACxB,IAAI;EACrC,CAAC;;EAED;EACA;EACA;EACA;;EAEA;EACA;EACAL,KAAK,CAACC,MAAM,CAAC6B,YAAY,GAAGkE,GAAG;EAC/B;EACA;EACAhG,KAAK,CAACC,MAAM,CAAC8B,aAAa,CAAC/B,KAAK,CAACC,MAAM,CAAC6B,YAAY,CAAC;;EAErD;EACA;;EAEA;EACA9B,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC4D,gBAAgB,GAAGjG,IAAI,CAACsF,OAAO;;EAEtD;AACF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASpE,MAAMA,CAAClB,IAAI,EAAEL,KAAK,EAAE;EAC3B;EACA,IACE,CAACA,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC6D,aAAa,IACrCpI,gBAAgB,CAACwF,QAAQ,CAACtD,IAAI,CAACsF,OAAO,CAAC,EACvC;IACA;EACF;;EAEA;EACA,IAAI3F,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC1C,KAAK,KAAK1B,aAAa,CAACgH,SAAS,EAAE;EAE9D/E,cAAc,CAACP,KAAK,EAAExB,QAAQ,CAAC6B,IAAI,CAAC,CAAC;;EAErC;EACA,IAAM2F,GAAG,GAAG;IACV9E,IAAI,EAAE7C,KAAK,CAACoD,SAAS,CAAC+E,OAAO;IAC7Bb,OAAO,EAAEtF,IAAI,CAACsF,OAAO;IACrBO,KAAK,EAAE3H,IAAI,CAAC4H,QAAQ,CAAC9F,IAAI,CAACsF,OAAO,CAAC;IAClCS,WAAW,EAAE,KAAK;IAClBC,cAAc,EAAE,KAAK;IACrBN,KAAK,EAAE,EAAE;IACTnE,QAAQ,EAAEC,oBAAoB,CAACxB,IAAI;EACrC,CAAC;;EAED;EACA;EACA;EACA;;EAEA;EACA;EACAL,KAAK,CAACC,MAAM,CAAC6B,YAAY,GAAGkE,GAAG;EAC/B;EACA;EACAhG,KAAK,CAACC,MAAM,CAAC8B,aAAa,CAAC/B,KAAK,CAACC,MAAM,CAAC6B,YAAY,CAAC;;EAErD;EACA;;EAEA;EACA;EACA;EACE;EACAkE,GAAG,CAACL,OAAO,KAAK3F,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC4D,gBAAgB;EACvD;EACCtG,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC1C,KAAK,KAAK1B,aAAa,CAACmI,MAAM;EACpD;EACAzG,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC1C,KAAK,KAAK1B,aAAa,CAACoI,OAAO;EACtD;EACA1G,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC1C,KAAK,KAAK1B,aAAa,CAACqI,WAAW,CAAC,EAC7D;IACA3G,KAAK,CAACC,MAAM,CAACyC,SAAS,CAAC1C,KAAK,GAAG1B,aAAa,CAACqG,IAAI;EACnD;AACF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASrF,YAAYA,CAACe,IAAI,EAAE;EAC1B,IAAMuG,IAAI,GAAGvG,IAAI,CAACa,IAAI,KAAK,MAAM,GAAGb,IAAI,CAACY,QAAQ,CAAC,CAAC,CAAC,GAAGZ,IAAI;EAC3D,OAAOwG,OAAO,CACZD,IAAI,KACDA,IAAI,CAAC1F,IAAI,KAAK,SAAS,IACrB0F,IAAI,CAAC1F,IAAI,KAAK,SAAS,IAAI0F,IAAI,CAACjB,OAAO,KAAK,MAAO,CAC1D,CAAC;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS9D,oBAAoBA,CAACxB,IAAI,EAAE;EAClC,IAAMyG,KAAK,GAAGrI,UAAU,CAAC4B,IAAI,CAAC,IAAI;IAChC6D,IAAI,EAAE/D,SAAS;IACf+E,MAAM,EAAE/E,SAAS;IACjBmE,MAAM,EAAEnE;EACV,CAAC;EACD,IAAM4G,GAAG,GAAGvI,QAAQ,CAAC6B,IAAI,CAAC,IAAI;IAC5B6D,IAAI,EAAE/D,SAAS;IACf+E,MAAM,EAAE/E,SAAS;IACjBmE,MAAM,EAAEnE;EACV,CAAC;;EAED;EACA,IAAMyB,QAAQ,GAAG;IACfoD,SAAS,EAAE8B,KAAK,CAAC5C,IAAI;IACrBe,QAAQ,EAAE6B,KAAK,CAAC5B,MAAM;IACtBC,WAAW,EAAE2B,KAAK,CAACxC,MAAM;IACzBL,OAAO,EAAE8C,GAAG,CAAC7C,IAAI;IACjBC,MAAM,EAAE4C,GAAG,CAAC7B,MAAM;IAClBb,SAAS,EAAE0C,GAAG,CAACzC;EACjB,CAAC;;EAED;EACA;EACA,OAAO1C,QAAQ;AACjB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASU,oBAAoBA,CAACjC,IAAI,EAAE;EAClC,OAAO,UAAU,IAAIA,IAAI,GACrBrC,eAAe,CAAA6H,aAAA,CAAAA,aAAA,KAAKxF,IAAI;IAAEY,QAAQ,EAAE;EAAE,EAAC,CAAC,GACxCjD,eAAe,CAACqC,IAAI,CAAC;AAC3B"},"metadata":{},"sourceType":"module","externalDependencies":[]}